{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Label</th>\n",
       "      <th>ClassName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16257</td>\n",
       "      <td>AnnualCrop/AnnualCrop_142.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>AnnualCrop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3297</td>\n",
       "      <td>HerbaceousVegetation/HerbaceousVegetation_2835...</td>\n",
       "      <td>2</td>\n",
       "      <td>HerbaceousVegetation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17881</td>\n",
       "      <td>PermanentCrop/PermanentCrop_1073.jpg</td>\n",
       "      <td>6</td>\n",
       "      <td>PermanentCrop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2223</td>\n",
       "      <td>Industrial/Industrial_453.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>Industrial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4887</td>\n",
       "      <td>HerbaceousVegetation/HerbaceousVegetation_1810...</td>\n",
       "      <td>2</td>\n",
       "      <td>HerbaceousVegetation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18895</th>\n",
       "      <td>4498</td>\n",
       "      <td>HerbaceousVegetation/HerbaceousVegetation_1952...</td>\n",
       "      <td>2</td>\n",
       "      <td>HerbaceousVegetation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18896</th>\n",
       "      <td>1149</td>\n",
       "      <td>Pasture/Pasture_1252.jpg</td>\n",
       "      <td>5</td>\n",
       "      <td>Pasture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18897</th>\n",
       "      <td>15489</td>\n",
       "      <td>AnnualCrop/AnnualCrop_2332.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>AnnualCrop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18898</th>\n",
       "      <td>6287</td>\n",
       "      <td>Residential/Residential_332.jpg</td>\n",
       "      <td>7</td>\n",
       "      <td>Residential</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18899</th>\n",
       "      <td>18613</td>\n",
       "      <td>PermanentCrop/PermanentCrop_856.jpg</td>\n",
       "      <td>6</td>\n",
       "      <td>PermanentCrop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18900 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID                                           Filename  Label  \\\n",
       "0      16257                      AnnualCrop/AnnualCrop_142.jpg      0   \n",
       "1       3297  HerbaceousVegetation/HerbaceousVegetation_2835...      2   \n",
       "2      17881               PermanentCrop/PermanentCrop_1073.jpg      6   \n",
       "3       2223                      Industrial/Industrial_453.jpg      4   \n",
       "4       4887  HerbaceousVegetation/HerbaceousVegetation_1810...      2   \n",
       "...      ...                                                ...    ...   \n",
       "18895   4498  HerbaceousVegetation/HerbaceousVegetation_1952...      2   \n",
       "18896   1149                           Pasture/Pasture_1252.jpg      5   \n",
       "18897  15489                     AnnualCrop/AnnualCrop_2332.jpg      0   \n",
       "18898   6287                    Residential/Residential_332.jpg      7   \n",
       "18899  18613                PermanentCrop/PermanentCrop_856.jpg      6   \n",
       "\n",
       "                  ClassName  \n",
       "0                AnnualCrop  \n",
       "1      HerbaceousVegetation  \n",
       "2             PermanentCrop  \n",
       "3                Industrial  \n",
       "4      HerbaceousVegetation  \n",
       "...                     ...  \n",
       "18895  HerbaceousVegetation  \n",
       "18896               Pasture  \n",
       "18897            AnnualCrop  \n",
       "18898           Residential  \n",
       "18899         PermanentCrop  \n",
       "\n",
       "[18900 rows x 4 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train=pd.read_csv('train.csv')\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "num_classes=train['ClassName'].nunique()\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KARAN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "c:\\Users\\KARAN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\KARAN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset,DataLoader\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self,path,transform):\n",
    "        self.data=pd.read_csv(path)\n",
    "        self.transform=transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path=self.data.iloc[index,1]\n",
    "        image=Image.open(img_path).convert('RGB')\n",
    "        label=self.data.iloc[index,2]\n",
    "        classname=self.data.iloc[index,3]\n",
    "        \n",
    "        if self.transform:\n",
    "            image=self.transform(image)\n",
    "            \n",
    "        return image,label,classname\n",
    "    \n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "path='train.csv'\n",
    "train=CustomDataset(path,transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x1e07f7e2510>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader=DataLoader(train,batch_size=64,shuffle=True)\n",
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='validation.csv'\n",
    "val=CustomDataset(path,transform)\n",
    "val_loader=DataLoader(train,batch_size=32,shuffle=True)\n",
    "\n",
    "path='test.csv'\n",
    "test=CustomDataset(path,transform)\n",
    "test_loader=DataLoader(test,batch_size=64,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KARAN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\KARAN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import vgg16\n",
    "import torch.nn as nn\n",
    "base_model = vgg16(pretrained=True)\n",
    "num_features = base_model.classifier[6].in_features\n",
    "base_model.classifier = nn.Sequential(\n",
    "    *list(base_model.classifier.children())[:-1]\n",
    ")\n",
    "print(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import GPyOpt\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "def get_model(num_layers, num_neurons, dropout, activation, weight_initializer, num_classes):\n",
    "    base_model = models.vgg16(pretrained=True)\n",
    "    for param in base_model.parameters():\n",
    "        param.requires_grad = False\n",
    "    num_features = base_model.classifier[6].in_features\n",
    "    base_model.classifier = nn.Sequential(\n",
    "        *list(base_model.classifier.children())[:-1]\n",
    "    )\n",
    "    layers = []\n",
    "    in_features = num_features\n",
    "    for i in range(num_layers):\n",
    "        layers.append(nn.Linear(in_features, num_neurons[i]))\n",
    "        layers.append(nn.ReLU(inplace=True))\n",
    "        layers.append(nn.Dropout(dropout[i]))\n",
    "        layers.append(nn.BatchNorm1d(num_neurons[i]))\n",
    "        in_features = num_neurons[i]\n",
    "    layers.append(nn.Linear(in_features, num_classes))\n",
    "    layers.append(nn.Softmax(dim=1))\n",
    "    model = nn.Sequential(\n",
    "        base_model,\n",
    "        *layers\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "try:\n",
    "    log_df = pd.read_csv('AutoFCL_results.csv', header=0, index_col=['index'])\n",
    "except FileNotFoundError:\n",
    "    log_df = pd.DataFrame(columns=['index', 'activation', 'weight_initializer', 'dropout', 'num_neurons', 'num_layers', 'train_loss', 'val_loss'])\n",
    "    log_df = log_df.set_index('index')\n",
    "\n",
    "\n",
    "# Define hyperparameter search space\n",
    "p_space = {\n",
    "    'activation': ['relu', 'tanh', 'sigmoid'], \n",
    "    'weight_initializer': ['he_normal'], \n",
    "    'num_layers': list(range(0, 2)) \n",
    "}\n",
    "\n",
    "p_space = list(product(*p_space.values()))\n",
    "\n",
    "# Loop over the hyperparameter combinations and conduct Bayesian optimization\n",
    "val_loss_min=np.Inf\n",
    "for combo in p_space:\n",
    "    activation, weight_initializer, num_layers = combo\n",
    "    bounds = [] \n",
    "    for i in range(num_layers): \n",
    "        bounds.append({'name': 'dropout' + str(i + 1), 'type': 'discrete', 'domain': [0, 0.1, 0.2, 0.3, 0.4, 0.5]})\n",
    "    for i in range(num_layers): \n",
    "        bounds.append({'name': 'num_neurons' + str(i + 1), 'type': 'discrete', 'domain': [2 ** j for j in range(6, 11)]})\n",
    "\n",
    "    def train_model(x):\n",
    "        # Extract dropout rates and number of neurons from the optimization parameters\n",
    "        dropouts = [float(x[:, i]) for i in range(0, num_layers)]\n",
    "        neurons = [int(x[:, i]) for i in range(num_layers, len(bounds))]\n",
    "        \n",
    "        # Create the model with the current set of hyperparameters\n",
    "        model = get_model(\n",
    "            num_layers=num_layers,\n",
    "            num_neurons=neurons,\n",
    "            dropout=dropouts,\n",
    "            activation=activation,\n",
    "            weight_initializer=weight_initializer,\n",
    "            num_classes=num_classes\n",
    "        )\n",
    "        \n",
    "        # Define the optimizer and criterion\n",
    "        optimizer = optim.Adagrad(model.parameters())\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        num_epochs=50\n",
    "        \n",
    "        # Train the model\n",
    "        train_loss = 0.0\n",
    "        for epoch in range(tqdm(range(num_epochs))):\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            for inputs, labels in train_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        # Compute validation loss\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in val_loader:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    val_loss += loss.item() * inputs.size(0)\n",
    "            train_loss = train_loss/len(train_loader.dataset)\n",
    "            val_loss = val_loss/len(val_loader.dataset)\n",
    "            \n",
    "            print(f'\\nTraining Loss: {train_loss:.4f} \\tValidation Loss: {val_loss:.4f}')\n",
    "            if val_loss <= val_loss_min:\n",
    "                torch.save(model.state_dict(), 'resnet101.pt')\n",
    "                val_loss_min = val_loss\n",
    "                \n",
    "        log_df.loc[len(log_df)] = [activation, weight_initializer, dropouts, neurons, num_layers, train_loss, val_loss]\n",
    "        \n",
    "        return val_loss\n",
    "    \n",
    "    # Create an instance of Bayesian optimization\n",
    "    opt_ = GPyOpt.methods.BayesianOptimization(f=train_model, domain=bounds)\n",
    "    \n",
    "    # Run the optimization\n",
    "    opt_.run_optimization(max_iter=5)\n",
    "    \n",
    "    # Save results to CSV\n",
    "    log_df.to_csv('AutoFCL_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def test(model, test_loader, criterion, device, num_classes):\n",
    "    model.eval()\n",
    "    class_correct = [0.0] * num_classes\n",
    "    class_total = [0.0] * num_classes\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            output = model(images)\n",
    "            loss = criterion(output, labels)\n",
    "            test_loss += loss.item() * images.size(0)\n",
    "            \n",
    "            _, predicted = torch.max(output, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            \n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "            \n",
    "            for i in range(len(labels)):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += (predicted[i] == labels[i]).item()\n",
    "                class_total[label] += 1\n",
    "    \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f'Test Loss: {test_loss:.4f}')\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        if class_total[i] > 0:\n",
    "            print(f'Accuracy of class {i}: {100 * class_correct[i] / class_total[i]:.2f}%')\n",
    "    \n",
    "    overall_accuracy = 100 * correct / total\n",
    "    print(f'Overall Accuracy: {overall_accuracy:.2f}%')\n",
    "    \n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=[f'Class {i}' for i in range(num_classes)]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
